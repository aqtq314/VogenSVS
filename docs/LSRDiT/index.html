<!DOCTYPE html>
<html>

<head>
  <title>LSRDiT Demo Page</title>
  <!-- Style source: https://github.com/simonlc/Markdown-CSS -->
  <style>
    html {
      font-size: 100%;
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
    }

    body {
      color: #444;
      font-family: 'Segoe UI', 'Helvetica Neue', sans-serif;
      font-size: 16px;
      line-height: 1.5em;
      padding: 1em;
      margin: auto;
      max-width: 1000px;
      background: #fefefe;
    }

    .subtitle {
      text-align: center;
    }

    p {
      margin: 1em 0;
    }

    img {
      max-width: 100%;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      font-weight: normal;
      color: #111;
      line-height: 1em;
      width: 100%;
    }

    .separator {
      display: flex;
      align-items: center;
      text-align: center;
      font-weight: 700;
      font-size: 80%;
      text-transform: uppercase;
      letter-spacing: 2px;
      margin-top: 80px;
      margin-bottom: 80px;
      color: #0005;
    }

    .separator::before,
    .separator::after {
      content: '';
      flex: 1;
      border-top: 2px solid #0003;
      border-bottom: 2px solid #0003;
      height: 1.5px;
    }

    .separator:not(:empty)::before {
      margin-right: 1em;
    }

    .separator:not(:empty)::after {
      margin-left: 1em;
    }


    h1 {
      margin-top: 100px;
      font-size: 3em;
      font-weight: normal;
      text-align: center;
    }

    h2 {
      font-size: 2em;
      text-align: center;
    }

    h3 {
      font-size: 1.5em;
    }

    .figure {
      text-align: center;
      width: 468px;
      margin-left: auto;
      margin-right: auto;
    }

    .caption {
      margin-top: 0.5em;
      text-align: left;
    }

    .linspec-group-container {
      display: flex;
      flex-wrap: wrap;
      justify-content: space-around;
    }

    .linspec-item-container {
      max-width: 300px;
      margin: 0 5px 20px 5px;
      display: inline-block;
      color: black;
      text-align: center;
      line-height: 1em;
    }

    .linspec-image-item {}

    .linspec-caption {
      font-size: 1.5em;
      font-weight: bold;
    }

    .linspec-caption-sub1 {
      font-size: 1.5em;
      font-weight: normal;
    }

    .linspec-caption-sub2 {
      font-size: 0.8em;
      font-weight: normal;
    }

    .audio-group-container {
      display: flex;
      flex-wrap: wrap;
      justify-content: space-around;
    }

    .audio-item-container {
      max-width: 420px;
      margin: 0 5px 20px 5px;
      display: inline-block;
      color: black;
      text-align: center;
      line-height: 1em;
    }

    .audio-item {
      width: 100%;
    }

    .lmagspec-image-item {}

    .audio-caption {
      font-size: 1.5em;
      font-weight: bold;
    }

    .audio-caption-sub1 {
      font-size: 1.5em;
      font-weight: normal;
    }

    .audio-caption-sub2 {
      font-size: 0.8em;
      font-weight: normal;
    }
  </style>
  <script src="../libs/vue@3.4.35/vue.global.prod.js"></script>
  <script type="module">
    const app = Vue.createApp({
      data() {
        return {
          sampleNames: [
            'BA FK 108+15',
            'BW ZXWDTYS 003+15',
            'DA SXQN 004+15',
            'DH BMG 024+15',
            'EU NSN 017+15',
            'SS CQ 220+15',
          ],
          linspecAlgorithms: [
            { filePart: '1-mdctGAN WAV 0-GT', caption: 'mdctGAN', captionSub1: '', captionSub2: '' },
            { filePart: '1-NUWave2 WAV 0-GT', caption: 'NU-Wave 2', captionSub1: '', captionSub2: '' },
            { filePart: '1-Vocos(Mel)', caption: 'Vocos', captionSub1: ' (from Mel)', captionSub2: '' },
            { filePart: '2-DDPM(100)', caption: 'LSRDiT', captionSub1: ' (proposed)', captionSub2: 'generated w/ DDPM, 100 steps' },
            { filePart: '2-DPM++2MKarras(50)', caption: 'LSRDiT', captionSub1: ' (proposed)', captionSub2: 'generated w/ DPM++ 2M Karras, 50 steps' },
            { filePart: '0-GT', caption: 'GT', captionSub1: '', captionSub2: '' },
          ],
          audioAlgorithms: [
            { filePart: '1-mdctGAN WAV 0-GT', caption: 'mdctGAN', captionSub1: '', captionSub2: '' },
            { filePart: '1-NUWave2 WAV 0-GT', caption: 'NU-Wave 2', captionSub1: '', captionSub2: '' },
            { filePart: '1-Vocos(Mel)', caption: 'Vocos', captionSub1: ' (from Mel)', captionSub2: '' },
            { filePart: '1-Vocos(Linear)', caption: 'Vocos', captionSub1: ' (from Lin. Spec.)', captionSub2: '' },
            { filePart: '2-DDPM(100)', caption: 'LSRDiT', captionSub1: ' (proposed) + Vocos', captionSub2: 'generated w/ DDPM, 100 steps' },
            { filePart: '2-DPM++2MKarras(50)', caption: 'LSRDiT', captionSub1: ' (proposed) + Vocos', captionSub2: 'generated w/ DPM++ 2M Karras, 50 steps' },
            { filePart: '0-GT', caption: 'GT', captionSub1: '', captionSub2: '' },
          ],
        };
      },
      methods: {
        getLinSpecImageSrc(sampleName, algorithm) {
          return `samples/WEBP LIN ${algorithm.filePart} ${sampleName}.webp`;
        },
        getLMagSpecImageSrc(sampleName, algorithm) {
          return `samples/WEBP LMAG ${algorithm.filePart} ${sampleName}.webp`;
        },
        getAudioSrc(sampleName, algorithm) {
          return `samples/OPUS ${algorithm.filePart} ${sampleName}.opus`;
        },
      },
      mounted() {
        const lazyLoad = (entries, observer) => {
          entries.forEach(entry => {
            if (entry.isIntersecting) {
              const element = entry.target;
              if (element.tagName === 'IMG' || element.tagName === 'AUDIO') {
                element.src = element.dataset.src;
                observer.unobserve(element);
              }
            }
          });
        };

        const observer = new IntersectionObserver(lazyLoad, {
          rootMargin: '0px 0px 50px 0px',
          threshold: 0.01
        });

        document.querySelectorAll('img[data-src], audio[data-src]').forEach(element => {
          observer.observe(element);
        });

        const audios = document.querySelectorAll('audio');
        audios.forEach(audio => {
          audio.addEventListener('play', () => {
            audios.forEach(otherAudio => {
              if (otherAudio !== audio) {
                otherAudio.pause();
              }
            });
          });
        });
      }
    });

    app.mount('#app');
  </script>
</head>

<body id="app">
  <h1>Extending Vocoder Bandwidth for Singing Voice Synthesis with Realistic Spectrogram</h1>

  <p>&nbsp;</p>

  <p><b>Abstract</b> This paper presents a novel approach to enhance the realism of vocoder-generated singing voice
    audio by addressing the distinguishable differences between synthetic and real-life recordings, particularly in
    high-frequency spectrogram components. We introduce an explicit linear spectrogram reconstruction step using
    denoising diffusion process before vocoder processing. By utilizing a refined neural network model architecture
    based on DiT that specializes in handling time-frequency data, we achieve high-fidelity spectrograms that are
    challenging for both humans and machine classifiers to differentiate from authentic recordings. Objective and
    subjective evaluations demonstrate that our reconstructed spectrograms successfully deceive both neural and human
    classifiers with minimal sacrifice in audio quality. This work presents a substantial advancement in overcoming the
    limitations of current vocoding techniques, particularly in the context of adversarial attacks on fake spectrogram
    detection.
  </p>

  <p>&nbsp;</p>

  <p>
  <div class="figure"><img data-src="figures/graphics export pipeline.svg" alt="Synthesis pipeline"></img></div>
  <div class="caption"><b>Figure</b> showing existing and proposed synthesis pipeline with linear spectrogram
    reconstruction.</div>
  </p>

  <p>&nbsp;</p>

  <p>
  <div class="figure"><img data-src="figures/graphics export model arch.svg" alt="Model architecture"></img></div>
  <div class="caption"><b>Figure</b> showing detailed model architecture of LSRDiT. Major modifications to DiT are
    highlighted in red.</div>
  </p>

  <div class="separator"> Separator </div>

  <h2>Linear Bank-Filtered Spectrogram Samples</h2>
  <div v-for="sampleName in sampleNames" class="linspec-group-container" :key="`linspec-group-${sampleName}`">
    <h3>{{ sampleName }}</h3>
    <div v-for="algorithm in linspecAlgorithms" class="linspec-item-container" :key="`linspec-item-${sampleName}-${algorithm.filePart}`">
      <img class="linspec-image-item" src="samples/WEBP(Placeholder) LIN.webp" :data-src="getLinSpecImageSrc(sampleName, algorithm)">
      <span class="linspec-caption">{{ algorithm.caption }}</span>
      <span class="linspec-caption-sub1">{{ algorithm.captionSub1 }}</span><br>
      <span class="linspec-caption-sub2">{{ algorithm.captionSub2 }}</span>
    </div>
  </div>

  <div class="separator"> Separator </div>

  <h2>Audio Samples</h2>
  <div v-for="sampleName in sampleNames" class="audio-group-container" :key="`audio-group-${sampleName}`">
    <h3>{{ sampleName }}</h3>
    <div v-for="algorithm in audioAlgorithms" class="audio-item-container" :key="`audio-item-${sampleName}-${algorithm.filePart}`">
      <img class="lmagspec-image-item" src="samples/WEBP(Placeholder) LMag.webp" :data-src="getLMagSpecImageSrc(sampleName, algorithm)">
      <audio class="audio-item" controls :data-src="getAudioSrc(sampleName, algorithm)"></audio>
      <span class="audio-caption">{{ algorithm.caption }}</span>
      <span class="audio-caption-sub1">{{ algorithm.captionSub1 }}</span><br>
      <span class="audio-caption-sub2">{{ algorithm.captionSub2 }}</span>
    </div>
  </div>

  <div class="separator"> End of Page </div>

  <div style="height: 500px;"></div>
</body>

</html>